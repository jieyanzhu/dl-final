{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyN8O/cbCvngHzn5EOJQZKzq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"XisyTthWC9ve","executionInfo":{"status":"error","timestamp":1691042411419,"user_tz":-540,"elapsed":847,"user":{"displayName":"Tom Zhu","userId":"03577365576940068264"}},"outputId":"08f4a12b-4c5f-4a90-a666-9fc5edb19a50"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-e4d9151c305c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1237\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspecial\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0monnx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m from . import (  # usort:skip. Keep the order instead of sorting lexicographically\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0m_deprecation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/errors.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_constants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdiagnostics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m __all__ = [\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/diagnostics/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from ._diagnostic import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mcreate_export_diagnostic_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdiagnose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mexport_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/diagnostics/_diagnostic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagnostics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minfra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcpp_backtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/diagnostics/infra/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from ._infra import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mDiagnosticOptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mGraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mInvocation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mLevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/diagnostics/infra/_infra.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFrozenSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagnostics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfra\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msarif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/diagnostics/infra/formatter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_beartype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagnostics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfra\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msarif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/diagnostics/infra/sarif/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# with extension for dataclasses and type annotation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagnostics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msarif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_address\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAddress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagnostics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msarif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_artifact\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArtifact\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagnostics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msarif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_artifact_change\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArtifactChange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/diagnostics/infra/sarif/_address.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagnostics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msarif\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_property_bag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.autograd as autograd\n","import matplotlib.pyplot as plt\n","import math\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","seed = 1234\n","torch.manual_seed(seed)\n","np.random.seed(seed)"],"metadata":{"id":"Ig2HjgibDGRh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the size of training data and validation data generated\n","num_train_1 = 2000\n","num_train_2 = 2000\n","num_val_1 = 500\n","num_val_2 = 500\n","\n","# Training data in class 1 has mean (0, 1.5) and variance 1\n","gaussian_1 = np.random.randn(num_train_1, 2) + np.concatenate((np.zeros((num_train_1, 1)), 1.5 * np.ones((num_train_1, 1))), axis=1)\n","label_1 = np.zeros(num_train_1)\n","\n","# Training data in class 2 has mean (0, -1.5) and variance 1\n","gaussian_2 = np.random.randn(num_train_2, 2) + np.concatenate((np.zeros((num_train_2, 1)), -1.5 *np.ones((num_train_2, 1))), axis=1)\n","label_2 = np.ones(num_train_2)\n","\n","x_train = np.concatenate((gaussian_1, gaussian_2), axis=0)\n","t_train = np.concatenate((label_1, label_2), axis=0)\n","\n","# Validation data in class 1 has mean (0, 1.5) and variance 1\n","gaussian_val_1 = np.random.randn(num_val_1, 2) + np.concatenate((np.zeros((num_val_1, 1)), 1.5 * np.ones((num_val_1, 1))), axis=1)\n","label_val_1 = np.zeros(num_val_1)\n","\n","# Validation data in class 2 has mean (0, -1.5) and variance 1\n","gaussian_val_2 = np.random.randn(num_val_2, 2) + np.concatenate((np.zeros((num_val_2, 1)), -1.5 * np.ones((num_val_2, 1))), axis=1)\n","label_val_2 = np.ones(num_val_2)\n","\n","x_val = np.concatenate((gaussian_val_1, gaussian_val_2), axis=0)\n","t_val = np.concatenate((label_val_1, label_val_2), axis=0)"],"metadata":{"id":"GtUybovsDIip"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class train_dataset(torch.utils.data.Dataset):\n","    def __init__(self, x_train, t_train):\n","        self.x_train = x_train\n","        self.t_train = t_train\n","\n","    def __len__(self):\n","        return self.x_train.shape[0]\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.x_train[idx], dtype=torch.float), torch.tensor(self.t_train[idx], dtype=torch.long)\n","\n","train_data = train_dataset(x_train, t_train)\n","val_data = train_dataset(x_val, t_val)"],"metadata":{"id":"86bsBlHuDVm2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prepare for batch training\n","batch_size = 20\n","\n","dataloader_train = torch.utils.data.DataLoader(\n","    train_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_val = torch.utils.data.DataLoader(\n","    val_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")"],"metadata":{"id":"ywhV1NURDgCs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def relu(x):\n","    # Use torch.where() to write ReLU\n","    x = torch.where(x > 0, x, torch.zeros_like(x))\n","    return x\n","\n","def softmax(x):\n","    # Substract each element in x by the maximum value on dimension 1\n","    x -= torch.cat([x.max(axis=1, keepdim=True).values] * x.size()[1], dim=1)\n","    x_exp = torch.exp(x)\n","    return x_exp/torch.cat([x_exp.sum(dim=1, keepdim=True)] * x.size()[1], dim=1)\n","\n","class Dense(nn.Module):\n","    def __init__(self, in_dim, out_dim, function=lambda x: x):\n","        super().__init__()\n","        # He Initialization\n","        # in_dim: input dimension; out_dim: output dimension\n","        # He initialization\n","        self.W = nn.Parameter(torch.tensor(np.random.uniform(\n","                        low=-np.sqrt(6/in_dim),\n","                        high=np.sqrt(6/in_dim),\n","                        size=(in_dim, out_dim)\n","                    ).astype('float32')))\n","        self.b = nn.Parameter(torch.tensor(np.zeros([out_dim]).astype('float32')))\n","        self.function = function\n","\n","    def forward(self, x):\n","        return self.function(torch.matmul(x, self.W) + self.b)\n","\n","\n","class MLP(nn.Module):\n","    def __init__(self, in_dim, hid_dim_1, hid_dim_2, out_dim):\n","        # equivalent to super().__init__() that enables inheritance\n","        super(MLP, self).__init__()\n","        self.linear1 = Dense(in_dim, hid_dim_1, function=relu)\n","        self.linear2 = Dense(hid_dim_1, hid_dim_2, function=relu)\n","        self.linear3 = Dense(hid_dim_2, out_dim, function=softmax)\n","\n","    def forward(self, x):\n","        x = self.linear1(x)\n","        x = self.linear2(x)\n","        x = self.linear3(x)\n","        return x"],"metadata":{"id":"b4QY8YBEDiFE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize hyperparameters\n","in_dim = 2\n","hid_dims_1 = [10, 20, 40, 80, 160]\n","hid_dims_2 = [10, 20, 40, 80, 160]\n","out_dim = 2\n","lr = 0.01\n","n_epochs = 5\n","realizations = 50"],"metadata":{"id":"yYZsVHQtDmBt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"id":"fSCwxk86Ipxe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the test set at each step to be a grid\n","x_coords = torch.arange(-2, 2, 0.02)\n","y_coords = torch.arange(-2, 2, 0.02)\n","x_test = torch.cartesian_prod(x_coords, y_coords)"],"metadata":{"id":"kB_25MvWJCqb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_decision_boundary(x_coords, y_coords, x_pred):\n","    '''Obtain the decision boundary from prediction data.'''\n","    # Initialize the decision boundary array\n","    decision_boundary = np.stack((x_coords.numpy(), np.zeros(len(x_coords))))\n","\n","    for i in range(len(x_coords)):\n","        # Retrieve all decisions along a vertical give x coordinate\n","        vert_decisions = x_pred[i*len(y_coords):(i+1)*len(y_coords)]\n","\n","        # Start from the middle of the vertical line to\n","        # decide the position of the decision boundary\n","        start_pos = int(len(y_coords)/2)\n","        for j in range(1, int(len(y_coords)/2)):\n","            if vert_decisions[start_pos+j, 2] != vert_decisions[start_pos+j-1, 2]:\n","                decision_boundary[1, i] = vert_decisions[start_pos+j, 1]\n","                break\n","            elif vert_decisions[start_pos-j, 2] != vert_decisions[start_pos-j+1, 2]:\n","                decision_boundary[1, i] = vert_decisions[start_pos-j, 1]\n","                break\n","\n","    return decision_boundary"],"metadata":{"id":"_HZK-qJXJNAx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train and save data for each network structure\n","for hid_dim_1, hid_dim_2 in zip(hid_dims_1, hid_dims_2):\n","    height_std_arr = np.zeros((realizations, n_epochs, math.ceil(train_data.__len__() / batch_size)))\n","    for i in range(realizations):\n","        # Initialize the network for each realization\n","        mlp = MLP(in_dim, hid_dim_1, hid_dim_2, out_dim).to(device)\n","        optimizer = optim.SGD(mlp.parameters(), lr=lr)\n","\n","        for epoch in range(n_epochs):\n","            losses_train = []\n","            losses_valid = []\n","            train_num = 0\n","            train_true_num = 0\n","            valid_num = 0\n","            valid_true_num = 0\n","            height_std = []\n","\n","            mlp.train() # Train mode for training (allow computation of gradients)\n","            for x, t in dataloader_train:\n","                # Convert true label to one-hot vector\n","                true = t.tolist()\n","                t_hot = torch.eye(2)[t]\n","\n","                # Move tensors to GPU\n","                x = x.to(device)\n","                t_hot = t_hot.to(device)\n","\n","                # Forward propagation\n","                # Equivalent to y = mlp.forward(x) since forward() is a built-in method of nn.Module class\n","                y = mlp(x)\n","\n","                # Compute loss function\n","                loss = -(t_hot * torch.log(y)).sum(axis=1).mean()\n","\n","                # Backprop\n","                optimizer.zero_grad()\n","                loss.backward()\n","\n","                # Update parameters\n","                optimizer.step()\n","\n","                # Convert model output to predicted values\n","                pred = y.argmax(dim=1)\n","\n","                losses_train.append(loss.tolist())\n","\n","                # Compute accuracy score\n","                acc = torch.where(t - pred.to(\"cpu\") == 0, torch.ones_like(t), torch.zeros_like(t))\n","                train_num += acc.size()[0]\n","                train_true_num += acc.sum().item()\n","\n","                # Collect test data to draw the decision boundary\n","                y = mlp(x_test.to(device))\n","                pred_test = y.argmax(dim=1)\n","\n","                x_pred = torch.cat((x_test.to(device), pred_test.reshape(-1, 1)), dim=1)\n","\n","                x_1_tensor = x_pred[x_pred[:, 2] == 0.0][:, :2]\n","                x_2_tensor = x_pred[x_pred[:, 2] == 1.0][:, :2]\n","\n","                decision_boundary = get_decision_boundary(x_coords, y_coords, x_pred)\n","                height_std.append(np.std(decision_boundary[1, :]))\n","\n","            height_std_arr[i, epoch, :] = height_std\n","\n","            mlp.eval() # Eval mode for training (disable computation of gradients)\n","            for x, t in dataloader_val:\n","                # Convert true label to one-hot vector\n","                true = t.tolist()\n","                t_hot = torch.eye(2)[t]\n","\n","                # Move tensors to GPU\n","                x = x.to(device)\n","                t_hot = t_hot.to(device)\n","\n","                # Forward propagation\n","                # Equivalent to y = mlp.forward(x) since forward() is a built-in method of nn.Module class\n","                y = mlp(x)\n","\n","                # Compute loss function\n","                loss = -(t_hot * torch.log(y)).sum(axis=1).mean()\n","\n","                pred = y.argmax(1)\n","\n","                # Convert model output to predicted values\n","                losses_valid.append(loss.tolist())\n","\n","                # Compute accuracy score\n","                acc = torch.where(t - pred.to(\"cpu\") == 0, torch.ones_like(t), torch.zeros_like(t))\n","                valid_num += acc.size()[0]\n","                valid_true_num += acc.sum().item()\n","\n","            # Plot the result for validation\n","            # plt.figure(figsize=(5, 5))\n","            # plt.plot(x_1_arr[:, 0], x_1_arr[:, 1], '.', label='class 1')\n","            # plt.plot(x_2_arr[:, 0], x_2_arr[:, 1], '.', label='class 2')\n","            # plt.xlabel(r'$x$')\n","            # plt.ylabel(r'$y$')\n","            # plt.legend(loc='best')\n","            # plt.show()\n","\n","\n","            print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(\n","                epoch,\n","                np.mean(losses_train),\n","                train_true_num/train_num,\n","                np.mean(losses_valid),\n","                valid_true_num/valid_num\n","            ))\n","\n","    with open('drive/MyDrive/deep-learning/final_project/width_data_'+str(hid_dim_1)+'.npy', 'wb') as f:\n","        np.save(f, height_std_arr)"],"metadata":{"id":"HAZCdHdFJP_E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Q9ystE0CkwE7"},"execution_count":null,"outputs":[]}]}